{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>MAKE A COPY OF THIS NOTEBOOK SO YOUR EDITS ARE SAVED</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq-JhCcLpBwS"
      },
      "source": [
        "\n",
        "We work for CC: ConscientiousCars, where we help self-driving vehicles be more conscientious of their surroundings. Our cars have been very good at recognizing and avoiding humans. They haven't, however, been capable of recognizing dogs. Since dogs are man's best friend and will always be where we humans are, we want our cars to know if a dog is on the road in front of them and avoid the dog!\n",
        "\n",
        "The first step to avoiding these cute puppies is **knowing if a puppy is in front of the car**. So today we will **build a detector that can tell when our car sees a dog or not**!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsGDD5lvQoBZ"
      },
      "source": [
        "In this notebook, you'll:\n",
        "- Explore the dogs vs. roads dataset\n",
        "- Train a simple K-neighbors classifier for computer vision\n",
        "- Train neural nets to tell dogs from roads\n",
        "- Improve your model with convolutional neural networks!\n",
        "- (Optional challenge) Use a saliency map to implement explainable AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhNVum16scIW"
      },
      "source": [
        "#@title Run this to load some packages and data! { display-mode: \"form\" }\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "def categorical_to_onehot(labels_in):\n",
        "  labels = []\n",
        "  for label in labels_in:\n",
        "    if label == 'dog':\n",
        "      labels.append(np.array([1, 0]))\n",
        "    else:\n",
        "      labels.append(np.array([0, 1]))\n",
        "  return np.array(labels)\n",
        "\n",
        "def one_hot_encoding(input):\n",
        "  output = np.zeros((input.size, input.max()+1))\n",
        "  output[np.arange(input.size), input] = 1\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  # Run this cell to download our data into a file called 'cifar_data'\n",
        "  !wget -O cifar_data https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
        "\n",
        "  # now load the data from our cloud computer\n",
        "  import pickle\n",
        "  data_dict = pickle.load(open( \"cifar_data\", \"rb\" ));\n",
        "\n",
        "  data   = data_dict['data']\n",
        "  labels = data_dict['labels']\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "def plot_one_image(data, labels, img_idx):\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  my_img   = data[img_idx, :].reshape([32,32,3]).copy()\n",
        "  my_label = labels[img_idx]\n",
        "  print(f'label: {my_label}')\n",
        "\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  img = ax.imshow(my_img.astype('uint8'), extent=[-1,1,-1,1])\n",
        "\n",
        "  x_label_list = [0, 8, 16, 24, 32]\n",
        "  y_label_list = [0, 8, 16, 24, 32]\n",
        "\n",
        "  ax.set_xticks([-1, -0.5, 0, 0.5, 1])\n",
        "  ax.set_yticks([-1, -0.5, 0, 0.5, 1])\n",
        "\n",
        "  ax.set_xticklabels(x_label_list)\n",
        "  ax.set_yticklabels(y_label_list)\n",
        "\n",
        "  fig.show(img)\n",
        "\n",
        "def logits_to_one_hot_encoding(input):\n",
        "    \"\"\"\n",
        "    Converts softmax output (logits) to a one-hot encoded format.\n",
        "\n",
        "    This function takes an array of softmax output probabilities\n",
        "    (usually from a neural network's output layer) and converts\n",
        "    each row to a one-hot encoded vector. The highest probability\n",
        "    in each row is marked as 1, with all other values set to 0.\n",
        "\n",
        "    Parameters:\n",
        "    input (numpy.ndarray): A 2D array where each row contains softmax probabilities for each class.\n",
        "                            The shape of the array is (n_samples, n_classes).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: A 2D array of the same shape as the input, where each row is the one-hot encoded representation\n",
        "                   of the class with the highest probability in the original row.\n",
        "    \"\"\"\n",
        "\n",
        "    output = np.zeros_like(input, dtype=int)\n",
        "    output[np.arange(len(input)), np.argmax(input, axis=1)] = 1\n",
        "    return output\n",
        "\n",
        "\n",
        "class CNNClassifier:\n",
        "    \"\"\"\n",
        "    A Convolutional Neural Network (CNN) classifier using Keras, customized for binary classification tasks.\n",
        "\n",
        "    This class wraps a Keras Sequential model with a specific architecture suitable for image classification tasks.\n",
        "    It includes a custom `predict` method that outputs one-hot encoded predictions, and other standard Keras model\n",
        "    methods are accessible as well. This was done to override the need for the SciKeras wrappers that is frequently\n",
        "    incompatible with Google Colab versions of Keras & Tensorflow. Feel free to modify as needed.\n",
        "\n",
        "    Attributes:\n",
        "        num_epochs (int): The number of training epochs.\n",
        "        layers (int): The number of convolutional layers in the model.\n",
        "        dropout (float): The dropout rate used in dropout layers for regularization.\n",
        "        model (keras.models.Sequential): The underlying Keras Sequential model.\n",
        "\n",
        "    Methods:\n",
        "        build_model(): Constructs the CNN model with the specified architecture and compiles it.\n",
        "\n",
        "        fit(*args, **kwargs): Trains the model. Accepts arguments compatible with the Keras `fit` method.\n",
        "\n",
        "        predict(*args, **kwargs): Predicts labels for the input data. Converts the softmax output of the model\n",
        "                                  to one-hot encoded format using `logits_to_one_hot_encoding`. Necessary to match\n",
        "                                  accuracy_score function expected arguments.\n",
        "\n",
        "        predict_proba(*args, **kwargs): Predicts labels for the input data and returns the raw output of the softmax.\n",
        "                                        Used when wanting to inspect the raw probabilistic scoring of the model.\n",
        "\n",
        "    Usage:\n",
        "        cnn_classifier = CNNClassifier(num_epochs=30, layers=4, dropout=0.5)\n",
        "        cnn_classifier.fit(X_train, y_train)\n",
        "        predictions = cnn_classifier.predict(X_test)\n",
        "\n",
        "    Note:\n",
        "        The `__getattr__` method is overridden to delegate attribute access to the underlying Keras model,\n",
        "        except for the `predict` method which is customized.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_epochs=30, layers=4, dropout=0.5):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.layers = layers\n",
        "        self.dropout = dropout\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((32, 32, 3)))\n",
        "\n",
        "        for i in range(self.layers):\n",
        "          model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "          model.add(Activation('relu'))\n",
        "\n",
        "        model.add(Conv2D(32, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(self.dropout))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(64, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(self.dropout))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(self.dropout))\n",
        "        model.add(Dense(2))\n",
        "        model.add(Activation('softmax'))\n",
        "        opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, *args, **kwargs):\n",
        "        return self.model.fit(*args, epochs=self.num_epochs, batch_size=10, verbose=2, **kwargs)\n",
        "\n",
        "    #NOTE: WRITTEN TO RETURN ONE HOT ENCODINGS FOR ACCURACY\n",
        "    def predict(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs)\n",
        "        return logits_to_one_hot_encoding(predictions)\n",
        "\n",
        "    def predict_proba(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs)\n",
        "        return predictions\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if name != 'predict' and name != 'predict_proba':\n",
        "            return getattr(self.model, name)\n",
        "        else:\n",
        "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
        "\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 7)\n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxGsnvhnn8R"
      },
      "source": [
        "# Understanding our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btr24O6Hqgo6"
      },
      "source": [
        "Our cars are very attentive and always have their eyes on the road.\n",
        "\n",
        "Every second, they're streaming in data about the street, including video.\n",
        "\n",
        "From this video data, we want our car to tell: is there 'road' or 'dog' in front of it?\n",
        "\n",
        "Lucky for us, we have a dataset of dog and road images already prepared! Let's start by reading that *labeled* data in.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmZbrZoKnthN"
      },
      "source": [
        "# load our data\n",
        "data, labels = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGO0FFnqdFne"
      },
      "source": [
        "Let's look at an image of a dog!\n",
        "\n",
        "Try changing the number below. What does it do?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csXB_FPMrx1D"
      },
      "source": [
        "plot_one_image(data, labels, 0) #change this number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYRzHTxVdSTG"
      },
      "source": [
        "### 💡 Discussion Question\n",
        "\n",
        "Why might we be using such blurry images?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Due to ease of processing and storage limitations, we use 32x32 pixel RGB images for our dataset of 1200 images. This choice also accommodates varying camera quality and speeds up model training due to the smaller number of weights needed to process lower resolution images.\n"
      ],
      "metadata": {
        "id": "YPRW3PQ2RN5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's try a road image. Again, try changing the number:"
      ],
      "metadata": {
        "id": "hnGnklImRU2z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsRj6BAqs25Y"
      },
      "source": [
        "plot_one_image(data, labels, 700) #change this number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Qx4UYxdbTK"
      },
      "source": [
        "How many images do we have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LQXCiGmAmz-"
      },
      "source": [
        "print(len(data))\n",
        "print(Counter(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OojOPMbLAl2B"
      },
      "source": [
        "The dataset is organized such that there are 600 images of dogs and 600 images of roads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sz2c5LlU7Sj"
      },
      "source": [
        "#### Optional Exercise: Examining More Images\n",
        "\n",
        "**Look at a few more images of both classes.**\n",
        "\n",
        "Try using a `for` loop to look at 5 images!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkcqdB2ZVoNc"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "for i in range(5):\n",
        "  plot_one_image(data, labels, i)\n",
        "\n",
        "for i in range(700, 705):\n",
        "  plot_one_image(data, labels, i)"
      ],
      "metadata": {
        "id": "BVCLOgJIEqUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHS0E_3wt0RS"
      },
      "source": [
        "##Understanding our Data Representation\n",
        "\n",
        "In an image each pixel is denoted by 3 numbers that represent the intensity value of that pixel (0 - 255) for each color channel (R, G, and B). Below we\n",
        "see a list of numbers for each image that represent the intensity values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlgF6jWit9jz"
      },
      "source": [
        "print('One image looks like:\\n', data[0], '\\n')\n",
        "print(\"Length of list:\", len(data[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPu7IDsZU_On"
      },
      "source": [
        "### 💡 Discussion Question\n",
        "\n",
        "What does each number mean? Can you explain the length of the list?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Each number represents the intensity of a color channel. We have 8 bits of info per channel or 256 possible values (ranging 0-255). Three color channels make up one color pixel (R G B). We have images that are 32 pixels wide and 32 pixels tall so $32 * 32 = 1024$ gives the total number of pixels, and multiplying this by the number of channels gives $3 * 1024 = 3072$, the total number of intensity values!\n"
      ],
      "metadata": {
        "id": "4YpV8uCERnQ_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWBX6fWUui4R",
        "cellView": "form"
      },
      "source": [
        "#@title Exercise: Fill in the correct values for each image's height, width, and number of color channels:\n",
        "\n",
        "img_height =  None#@param {type:\"integer\"}\n",
        "img_width =  None#@param {type:\"integer\"}\n",
        "color_channels =  None#@param {type:\"integer\"}\n",
        "\n",
        "if img_height == 32 and img_width == 32 and color_channels == 3:\n",
        "  print(\"Correct!\")\n",
        "  print (\"Each image is\", img_height, 'x', img_width, 'pixels.')\n",
        "  print (\"Each pixel has\", color_channels, \"channels for red, green, blue.\")\n",
        "  print (\"This gives a total of\", img_height * img_width * color_channels, \"intensity values per image.\")\n",
        "else:\n",
        "  print(\"Those aren't quite the values.\")\n",
        "  print(\"Your values give a total of\", img_height * img_width * color_channels, \"intensity values per image.\")\n",
        "  print(\"Discuss with your group and try again!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "**img_height:** 32<br>\n",
        "**img_width:** 32<br>\n",
        "**color_channels:** 3"
      ],
      "metadata": {
        "id": "nswOQp5JSyoE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-haNvnOwt-YE"
      },
      "source": [
        "We use these values as **inputs** to predict an **output** label: 'dog' or 'road'!\n",
        "\n",
        "Here's what our entire dataset looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZIiCuBrvS6z"
      },
      "source": [
        "print ('Data shape:', data.shape)\n",
        "print ('Data:\\n', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUjr5CKnhvtg"
      },
      "source": [
        "#A Simple Machine Learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPskDCqlzOEE"
      },
      "source": [
        "We want to create a machine learning model that can tell us whether a new image is either a dog or a road.\n",
        "\n",
        "We will give our model a training manual of data and labels that it will study or train on.\n",
        "\n",
        "We then check how well our model is doing on a test, where it is given data and told to predict their labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0tDoNWFVVYB"
      },
      "source": [
        "##Building a KNN##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8_JZ9PVzKzr"
      },
      "source": [
        "Let's start by using the `KNeighborsClassifier` model.\n",
        "\n",
        "**Playground:** Explore [this demo](http://vision.stanford.edu/teaching/cs231n-demos/knn/) to understand what the KNN model is doing!\n",
        "\n",
        "**Exercise:** Below, please build, train, and measure the accuracy of your own KNN model. Experiment with changing the number of neighbors!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFOgS2VEyTkH"
      },
      "source": [
        "# Preparing data and create training and test inputs and labels\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# Initialize our model\n",
        "knn_model = None # Change this!\n",
        "\n",
        "# Train our model\n",
        "\n",
        "# Test our model\n",
        "\n",
        "# Print the score on the testing data\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUtugsglYkSJ"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "\n",
        "# Preparing data and create training and test inputs and labels\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "# Initializing our model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Training our model with its training input data and labels\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict what the classes are based on the testing data\n",
        "predictions = knn_model.predict(X_test)\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(\"KNN Testing Set Accuracy:\")\n",
        "print(accuracy_score(y_test, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1ZgBtyIHYr7"
      },
      "source": [
        "**(Optional):** After you've built your KNN model, remove ```random_state=1``` and re-run the cells above. How does removing ```random_state=1``` affect your accuracy? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Eliminating the `random_state=1` parameter changes how the data is split between the training and testing sets. Since computers cannot truly be random in that they execute specific calculations asked of them, computers cannot generate truly random numbers and instead generate pseudorandom numbers. The generator algorithms take in a \"seed\" that will always result in the same \"random\" numbers produced. This means using the same seed will always give you the same train-test split!\n",
        "\n",
        "For extra exploration, try changing the `shuffle` parameter, which is `True` by default, to see what happens when the data isn't randomly split between the training and testing sets."
      ],
      "metadata": {
        "id": "SuFQmYhWR8hn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU48O9l18_-C"
      },
      "source": [
        "##Predicting on images\n",
        "\n",
        "We can use our trained model to predict whether our car is seeing a `dog` or `road`. Let's try this out - experiment with different images!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1_moLl9E0B"
      },
      "source": [
        "# Specify which image you want to show\n",
        "image_id = 210 #Change this!\n",
        "\n",
        "# Visualize the image\n",
        "plot_one_image(X_test, y_test, image_id)\n",
        "\n",
        "# Use the model to predict what this might be and print it\n",
        "print('prediction:', knn_model.predict([X_test[image_id]])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oW_Wb-1CTfB"
      },
      "source": [
        "## ✍ Exercise: Choosing a value of k\n",
        "\n",
        "Determine the optimal value of \"k\" for our data. Use a for loop to loop through different values of \"k\". In particular, *at the very least* try k = 1, 3, 5, 10, 20, and 30. For each of these values of \"k\", define a new KNN model, train it, and evaluate the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrZK_qoAZOAd"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjefvviV3HN"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "\n",
        "for i in [1, 3, 5, 10, 20, 30]:\n",
        "  # Defining our classifier\n",
        "  knn_model = KNeighborsClassifier(n_neighbors=i)\n",
        "\n",
        "  # Training our model with its training input data and labels\n",
        "  knn_model.fit(X_train, y_train)\n",
        "\n",
        "  # predictions for test\n",
        "  predictions = knn_model.predict(X_test)\n",
        "\n",
        "  # Print the score on the testing data\n",
        "  print(f\"KNN testing set accuracy for {i} neighbors: {accuracy_score(y_test, predictions)*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ9uYgKMCX-z"
      },
      "source": [
        "**Discuss:** What are the advantages and disadvantages of using a bigger vs. smaller **k**? What is the optimal value?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "A smaller 'k' value is effective for distinct clusters but will be sensitive to outliers and noise. A larger 'k' suits datasets with overlapping clusters but will decrease the influence of the closest data.\n",
        "\n",
        "For this dataset, an optimal 'k' is typically found to be either 2 or between 11-16."
      ],
      "metadata": {
        "id": "iJGrMK1iSeSE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j09evSD_YfJ4"
      },
      "source": [
        "## (Optional Exercise) Understanding our mistakes\n",
        "\n",
        "Our classifications are OK, but are they good enough for our conscientious cars?\n",
        "\n",
        "Let's put on our detective hats to determine the root causes of the incorrect classifications!\n",
        "\n",
        "Below, please print out 4 images of true positives, 4 images of true negatives, 4 images of false positives, and 4 images of false negatives. What are the reasons for failure (both for false positives and false negatives)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWy1S_gyGoJT"
      },
      "source": [
        "#True Positives (code provided)\n",
        "print (\"TRUE POSITIVES\")\n",
        "tp_count = 0\n",
        "i = 0\n",
        "while tp_count < 4 and i < len(X_test):\n",
        "  prediction = knn_model.predict([X_test[i]])[0]\n",
        "  if prediction == y_test[i] and prediction == 'dog':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    tp_count += 1\n",
        "  i += 1\n",
        "\n",
        "#False Positives\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#True Negatives\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#False Negatives\n",
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU-cZuCnG7Yy",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "# True Positives\n",
        "print (\"TRUE POSITIVES\")\n",
        "tp_count = 0\n",
        "i = 0\n",
        "while tp_count < 4 and i < len(X_test):\n",
        "  prediction = knn_model.predict([X_test[i]])[0]\n",
        "  if prediction == y_test[i] and prediction == 'dog':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    tp_count += 1\n",
        "  i += 1\n",
        "\n",
        "# False Positives\n",
        "print (\"FALSE POSITIVES\")\n",
        "fp_count = 0\n",
        "i = 0\n",
        "while fp_count < 4 and i < len(X_test):\n",
        "  prediction = knn_model.predict([X_test[i]])[0]\n",
        "  if prediction != y_test[i] and prediction == 'dog':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    fp_count += 1\n",
        "  i += 1\n",
        "\n",
        "# True Negatives\n",
        "print (\"TRUE NEGATIVES\")\n",
        "tn_count = 0\n",
        "i = 0\n",
        "while tn_count < 4 and i < len(X_test):\n",
        "  prediction = knn_model.predict([X_test[i]])[0]\n",
        "  if prediction == y_test[i] and prediction == 'road':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    tn_count += 1\n",
        "  i += 1\n",
        "\n",
        "\n",
        "# False Negatives\n",
        "print (\"FALSE NEGATIVES\")\n",
        "fn_count = 0\n",
        "i = 0\n",
        "while fn_count < 4 and i < len(X_test):\n",
        "  prediction = knn_model.predict([X_test[i]])[0]\n",
        "  if prediction != y_test[i] and prediction == 'road':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    fn_count += 1\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSx8HEhHKxFd"
      },
      "source": [
        "### 💡 Discussion Question\n",
        "What patterns did you notice? What are some reasons that the model makes mistakes?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Generally the false classifications are images that are much closer to the subject. One reason the model may make mistakes is that these images are on the boundaries of their clusters."
      ],
      "metadata": {
        "id": "i4cY1UFoTE1i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doLXp1Ot8D2C"
      },
      "source": [
        "#Neural Networks\n",
        "Now, let's create some new models using neural networks!\n",
        "\n",
        "You can play around with [TensorFlow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.62283&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&learningRate_hide=true&batchSize_hide=true&stepButton_hide=true&activation_hide=true) to get a feel for how neural nets work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9iFe-B4zqQA"
      },
      "source": [
        "To build a simple neural network, we use `MLPClassifier` from scikit-learn. We will play with the **number of neurons** and the **number of hidden layers** to adjust the complexity of our model, just like we did in Playground!\n",
        "\n",
        "**Example 1:**\n",
        "Here's how we create a neural network with 1 hidden layer of 3 neurons.\n",
        "\n",
        "```python\n",
        "nnet = MLPClassifier(hidden_layer_sizes=(3))\n",
        "```\n",
        "\n",
        "**Example 2:**\n",
        "\n",
        "Here's how we create a neural network with 2 hidden layers: one of 3 neurons and one of 4 neurons.\n",
        "\n",
        "```python\n",
        "nnet = MLPClassifier(hidden_layer_sizes=(3, 4))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍ Exercise\n",
        "How might you build a neural network with 3 hidden layers? Run the code below and modify it!"
      ],
      "metadata": {
        "id": "9sOCUy7iTPVs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4XblMWBzm96"
      },
      "source": [
        "# Create and train our multi layer perceptron model\n",
        "nnet = MLPClassifier(hidden_layer_sizes=(3), random_state=1, max_iter=10000000)  ## How many hidden layers? How many neurons does this have?\n",
        "nnet.fit(X_train, y_train)\n",
        "\n",
        "# Predict what the classes are based on the testing data\n",
        "predictions = nnet.predict(X_test)\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(\"MLP Testing Accuracy:\")\n",
        "print(accuracy_score(y_test, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution (3-Layer MLP Example)\n",
        "# Note that this is an example- have your students find a better architecture.\n",
        "\n",
        "# Create and train our multi layer perceptron model\n",
        "nnet = MLPClassifier(hidden_layer_sizes=(10, 5, 4), random_state=1, max_iter= 10000)  ## How many hidden layers? How many neurons does this have?\n",
        "nnet.fit(X_train, y_train)\n",
        "\n",
        "# Predict what the classes are based on the testing data\n",
        "predictions = nnet.predict(X_test)\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(\"MLP Testing Accuracy:\")\n",
        "print(accuracy_score(y_test, predictions)*100)"
      ],
      "metadata": {
        "id": "6OAOvtduPV3j",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1QYZTxq0RCV"
      },
      "source": [
        "**How well did your neural network perform?**\n",
        "\n",
        "Multilayer perceptrons are more complex models and it can be difficult to find the right \"settings\" for them. It takes some trial and error!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX27P2eY0yqQ"
      },
      "source": [
        "**Exercise: try the following out and see how well you can get your network to do!**\n",
        "* Train a 1 layer, 10 neuron network for practice\n",
        "* Change the number of neurons and/or add layers to see how well you can do\n",
        "* Increase or decrease the number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPOrTN-JMYk"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXud5MuBXqzo"
      },
      "source": [
        "### ✍ Exercise: Automating our Experiments\n",
        "\n",
        "Similar to what you did for KNNs, use a for loop to automate your investigation. Explore different numbers of hidden layers, the size of the hidden layers, and the number of iterations! How well can you get your network performing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owrF6cDvX0HX"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDtG4wESX263"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "for layers in [(1,1), (3,3), (5,5), (8,6), (10,10,10), (10,10,5)]:\n",
        "\n",
        "  print('Layer params are ...')\n",
        "  print(layers)\n",
        "  nnet = MLPClassifier(hidden_layer_sizes=layers, random_state=1, max_iter=100)  ## How many hidden layers? How many neurons does this have?\n",
        "\n",
        "  nnet.fit(X_train, y_train)\n",
        "\n",
        "  # Predict what the classes are based on the testing data\n",
        "  predictions = nnet.predict(X_test)\n",
        "\n",
        "  # Print the score on the testing data\n",
        "  print(\"MLP Testing Accuracy:\")\n",
        "  print(accuracy_score(y_test, predictions) * 100)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37O_VE_D1Bdy"
      },
      "source": [
        "# Models for Vision: Convolutional Neural Networks\n",
        "There is a famous type of neural network known as convolutional neural networks (CNNs). These types of neural networks work particularly well on problems to do with computer vision. Let's try one out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqrfI4JiVeFr"
      },
      "source": [
        "# CNNClassifier\n",
        "\n",
        "## Overview\n",
        "The `CNNClassifier` is a custom class designed for Inspirit AI focusing on teaching the application of Convolutional Neural Networks (CNN) for binary classification tasks using Keras. This class is unique and is not available from any standard libraries or repositories.\n",
        "\n",
        "## Description\n",
        "This class encapsulates a Keras Sequential model tailored for image classification. It features a customized `predict` method for one-hot encoded outputs, which bypasses the need for SciKeras wrappers that often present compatibility issues with certain versions of Keras and TensorFlow on Google Colab. The design encourages experimentation and modification to suit different learning or project needs. Take a look in the large import box above to see its definition!\n",
        "\n",
        "## Attributes\n",
        "- `num_epochs` (int): Number of training epochs.\n",
        "- `layers` (int): Number of convolutional layers.\n",
        "- `dropout` (float): Dropout rate for regularization.\n",
        "- `model` (keras.models.Sequential): The base Keras Sequential model.\n",
        "\n",
        "## Methods\n",
        "- `build_model()`: Sets up the CNN architecture and compiles the model.\n",
        "- `fit(*args, **kwargs)`: Trains the model using parameters compatible with Keras’s `fit` method.\n",
        "- `predict(*args, **kwargs)`: Outputs one-hot encoded predictions.\n",
        "- `predict_proba(*args, **kwargs)`: Provides raw softmax output for detailed probabilistic analysis.\n",
        "\n",
        "### Training Your CNN with One Hot Encoded Labels\n",
        "For initiating a basic CNN in Keras, execute the following command:\n",
        "\n",
        "`cnn = CNNClassifier(num_epochs=N)`\n",
        "\n",
        "Here, `num_epochs` denotes the number of complete passes the neural network will make through the training dataset.\n",
        "\n",
        "Before training, it's crucial to preprocess our data. Specifically, we need to convert the data to floating-point (decimal) numbers. Additionally, our current labels, which are string categories like \"dog\" or \"road\", must be transformed into one-hot encodings. This conversion is essential for the neural network to process them correctly.\n",
        "\n",
        "**Exercise:** Convert your string labels to one-hot encodings using `categorical_to_onehot(data)`, then proceed to train and test your CNN using the modified data. Make sure to save these variables as `y_train_onehot` and `y_test_onehot` We've taken care of changing the data (`X_train` & `X_test`) to decimal numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwghlVU4WTy"
      },
      "source": [
        "# convert our data to floats for our CNN\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "\n",
        "# convert our labels to one-hot vectors!\n",
        "\n",
        "\n",
        "### YOUR CODE HERE\n",
        "# Create and train our cnn\n",
        "\n",
        "# Predict what the classes are based on the testing data\n",
        "\n",
        "# Print the score on the testing data\n",
        "\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVozcO7TYWdn"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# convert our data to floats for our CNN\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "\n",
        "# convert our labels to one-hot vectors!\n",
        "y_test_onehot = categorical_to_onehot(y_test)\n",
        "y_train_onehot = categorical_to_onehot(y_train)\n",
        "\n",
        "# Create and train our CNN model\n",
        "cnn = CNNClassifier(num_epochs=40)\n",
        "\n",
        "cnn.fit(X_train, y_train_onehot)\n",
        "\n",
        "# Predict what the classes are based on the testing data\n",
        "predictions = cnn.predict(X_test)\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(\"CNN Testing Set Score:\")\n",
        "print(accuracy_score(y_test_onehot, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWpgsVXP1ut"
      },
      "source": [
        "**Discuss: Is this CNN good enough to use in practice?**\n",
        "\n",
        "CNNs typically perform better than basic Neural Networks on vision problems - but like basic Neural Networks, they aren't always consistent in their results and are sensitive to a number of factors.\n",
        "\n",
        "If you're interested in learning more about CNNs, spend some time exploring the [CNN Explainer](https://poloclub.github.io/cnn-explainer/)!\n",
        "\n",
        "**Report to the class your highest model accuracy.**\n",
        "\n",
        "**Bonus Question:** Each of you might see a different max accuracy. Can you think of why that might be?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Hint: *Consider the stages in the machine learning process.* The data is split into training and testing sets randomly, so the model learns from varying data each time. Additionally, neural network performance is influenced by multiple parameters, such as initialization, which can result in different outcomes."
      ],
      "metadata": {
        "id": "9-F39fv3TicV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XRh5Y5P_CL"
      },
      "source": [
        "## Training and Validation Curves\n",
        "\n",
        "An important aspect of training neural networks is to prevent overfitting. **How do you know when your model is overfitting?**\n",
        "\n",
        "To plot our model's history, we can train it with\n",
        "```\n",
        "history = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot))\n",
        "```\n",
        "\n",
        "and then use\n",
        "```\n",
        "plot_acc(history)\n",
        "```\n",
        "Don't forget to change ```model``` to be the name of your model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eaFvE2PQEFe"
      },
      "source": [
        "**Exercise:** Train a CNN model and plot a train vs. test curve.\n",
        "\n",
        "**After how many epochs does the model begin to overfit?** Overfitting occurs when the validation accuracy starts to drop below the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsVAasDbjARJ"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMsb61vccItm"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "\n",
        "cnn = CNNClassifier(num_epochs=20)\n",
        "\n",
        "history = cnn.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot))\n",
        "\n",
        "plot_acc(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVzEpI_xWpE5"
      },
      "source": [
        "### Hopefully your CNN worked *very* well! We want to keep the doggos as safe as they can be.\n",
        "\n",
        "![](https://images.pexels.com/photos/316/black-and-white-animal-dog-pet.jpg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1wGoQPm2Ko"
      },
      "source": [
        "# Challenge Exercise: Explainability through Saliency Maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnGTR2Vdb08i"
      },
      "source": [
        "Neural networks have achieved incredible results in many fields. But they have a big problem: it’s very difficult to explain exactly why a neural network makes the decisions it does. This makes it difficult to trust them in high-stakes applications like medicine, self-driving cars, and criminal justice - would you trust an AI that diagnosed you with a disease, but couldn’t explain why?\n",
        "\n",
        "Other classifiers are much more explainable:\n",
        "\n",
        "*   With logistic regression, we can see the coefficient (importance) attached to each input feature.\n",
        "*   With a decision tree, we can trace a particular decision down the tree.\n",
        "*   With KNN, we can examine the nearby neighbors.\n",
        "\n",
        "Our CNN, above, works well. For example, let's try choosing an image from our dataset and classifying it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmU6Peb7m67F"
      },
      "source": [
        "image_index = 220 # pick any image you'd like\n",
        "input_image = X_test[image_index]\n",
        "print(input_image.shape)\n",
        "print(input_image) # How many numbers are there? What does each represent?\n",
        "\n",
        "plt.imshow(input_image.reshape(32,32,3).astype(int))\n",
        "plt.show()\n",
        "\n",
        "print('Classification:')\n",
        "if(np.argmax(cnn.predict(np.array([input_image]))) == 0):\n",
        "  print(\"Predicted: Dog\")\n",
        "else:\n",
        "  print(\"Predicted: Road\")\n",
        "# 0 means dog, 1 means road"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6P7DX_WcfOU"
      },
      "source": [
        "But why did the CNN reach that decision? It’s really hard to give a clear answer! The CNN relies on multiplying input features by the weights it has set. You can print out and look at the hundreds of weights:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8M8UZCgcpqO"
      },
      "source": [
        "# Warning: expect a large output!\n",
        "for layer_weights in history.model.weights:\n",
        "  print (layer_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR42boMgczoF"
      },
      "source": [
        "Unfortunately, that probably didn’t help you make a useful explanation.\n",
        "\n",
        "Researchers are currently studying ways to make neural networks more explainable. One approach is using **saliency maps** to figure out the saliency (importance) of each individual pixel. Check out a demo [here](https://lrpserver.hhi.fraunhofer.de/image-classification). Intuitively, we're trying to understand the neural network by tracking what it \"pays attention\" to, in the same way that psychologists study babies' cognition by [tracking what babies look at](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3259733/).\n",
        "\n",
        "In this exercise, we're going to build a simple version of a saliency map for the image you chose above. We'll see what pixels were most important in helping the network make its classification.\n",
        "\n",
        "To do this, we'll investigate the effects of changing each pixel a little bit. If changing a particular pixel changes the result a lot, we conclude that pixel must be important for classifying. If changing that pixel doesn't change the result, we conclude that pixel is unimportant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RpZL6ChfLZ6"
      },
      "source": [
        "We're going to use the raw predicted probabilities, rather than the final classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkdMS7sJfR6j"
      },
      "source": [
        "pred = cnn.predict_proba(np.array([input_image])) # What does each number mean?\n",
        "print(pred)\n",
        "dog_prob = pred[0][0] # This is the probability we'll use (if we know dog prob, we know the classification)\n",
        "\n",
        "print('Probability of dog:')\n",
        "print(dog_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xla3j0R1geJY"
      },
      "source": [
        "Now, we need to calculate the saliency for each pixel (really, each RGB value). The core idea is that a pixel's saliency is the average value of\n",
        "\n",
        " $D = \\left|\\frac{\\Delta probability}{\\Delta pixel}\\right|$\n",
        "\n",
        " where $\\Delta$ is the amount of change. If a small change in the pixel value results in a large change in the probability (either up or down), we know this pixel is important. If you've seen derivatives in calculus, this idea should feel familiar.\n",
        "\n",
        "Here's the game plan:\n",
        "\n",
        "*   Consider each pixel value in turn: R, G, B, then the next pixel.\n",
        "*   Make a copy of the image array before you change anything!\n",
        "*   Make the pixel value larger or smaller by various amounts. Each time, find the CNN's prediction with the changed value, and calculate the value of D.\n",
        "*   Repeat the previous step a few times, and calculate the pixel's saliency: the average value of D.\n",
        "*   Store the saliency of each pixel in a list, so that we can visualize it later.\n",
        "\n",
        "Try it below! (Warning: this code might be very slow. As a further challenge, try to speed it up!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnABhKUJmNCF"
      },
      "source": [
        "saliencies = [] # eventually, will be the same size as input_image\n",
        "\n",
        "for index, pixel in enumerate(input_image):\n",
        "  # index counts up from 0, pixel is between 0 and 255\n",
        "\n",
        "  if index % 100 == 0: # will track progress - this might take a while\n",
        "    print (index)\n",
        "\n",
        "  changed_input = input_image.copy() # make sure not to change the original input_image!\n",
        "\n",
        "  # YOUR CODE HERE:\n",
        "  # In changed_input, change the value of this pixel by some amount.\n",
        "  # Use the CNN to classify changed_input.\n",
        "  # Calculate the value of D.\n",
        "  # Repeat with various-size changes, and calculate saliency as the average D.\n",
        "  saliency = 0 # Change this!\n",
        "\n",
        "  saliencies.append(saliency)\n",
        "\n",
        "print(saliencies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFpQH9ZpjQ-A",
        "cellView": "form"
      },
      "source": [
        "#@title Faster Student submitted solution\n",
        "# Thanks to Paul Cherian (Inspirit AI Winter 2020 Student) for this solution!\n",
        "\n",
        "saliencies = [] #eventually, will be the same size as input_image\n",
        "all_changed_pixels = []\n",
        "pixel_differences = []\n",
        "for index, pixel in enumerate(input_image):\n",
        "  #index counts up from 0, pixel is between 0 and 255\n",
        "  # if index%100 == 0: #will track progress - this might take a while\n",
        "    # print (index)\n",
        "  # if index>500:\n",
        "  #   break\n",
        "  changed_input = input_image.copy() #make sure not to change the original input_image!\n",
        "\n",
        "  # A much faster approach would be vectorize - create an array with all the changed\n",
        "  #versions so that we can feed them all into the CNN at the same time.\n",
        "  D_list = []\n",
        "  changed_versions_of_pixel = []\n",
        "\n",
        "  for pixel_change in [-50, -30, -10, 10, 30, 50]:\n",
        "    changed_pixel = pixel + pixel_change\n",
        "\n",
        "    if 0 <= changed_pixel <= 255:\n",
        "      #add all the changed pixels to a list\n",
        "      changed_versions_of_pixel.append(changed_pixel)\n",
        "      pixel_differences.append(pixel- changed_pixel)\n",
        "\n",
        "  # add the list of changed pixels to another list\n",
        "  all_changed_pixels.append(changed_versions_of_pixel)\n",
        "\n",
        "# make a 'stack' of all images with their changed pixel in each by using the\n",
        "#changed input as the template and then reverting it back to the original when\n",
        "# we move to the next pixel\n",
        "changed_images = []\n",
        "\n",
        "for j in range(len(changed_input)):\n",
        "    for i in range(len(all_changed_pixels[j])):\n",
        "      changed_input[j]= all_changed_pixels[j][i]\n",
        "      changed_images.append(changed_input)\n",
        "      changed_input = input_image.copy()\n",
        "\n",
        "a = cnn.predict_proba(np.array([input_image]))\n",
        "b = cnn.predict_proba(np.array(changed_images))\n",
        "\n",
        "a = np.log(a)\n",
        "b = np.log(b)\n",
        "\n",
        "dog_prob = a[0][0]\n",
        "new_b = []\n",
        "for i in b:\n",
        "  new_b.append(abs(i[0]) + abs(i[1]))\n",
        "new_b = np.array(new_b)\n",
        "probability_changes = new_b - dog_prob\n",
        "d_total = abs(probability_changes/pixel_differences)\n",
        "\n",
        "# the d_total list is all the values of D for each pixel with it's changes, it\n",
        "# needs to be averaged, but because we ommitted some changed values that were not\n",
        "# in the 0-255 range, use 'start' to 'end' to splice the array.\n",
        "\n",
        "start = 0\n",
        "end = 0\n",
        "for i in all_changed_pixels:\n",
        "  end += len(i)\n",
        "  saliency = (np.mean(d_total[start:end]))\n",
        "  start = end\n",
        "  saliencies.append(saliency)\n",
        "\n",
        "print(\"Non-Normalized Saliencies: \\n\", saliencies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9jaa4VMvFTr",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "#Slow, simpler version.\n",
        "#A much faster approach would be vectorize - create an array with all the changed\n",
        "#versions so that we can feed them all into the CNN at the same time.\n",
        "\"\"\"\n",
        "saliencies = []\n",
        "for index, pixel in enumerate(input_image):\n",
        "  if index%100 == 0: #track progress\n",
        "    print (index)\n",
        "  changed_input = input_image.copy()\n",
        "  D_list = []\n",
        "  for pixel_change in [-50, -30, -10, 10, 30, 50]:\n",
        "    changed_pixel = pixel + pixel_change\n",
        "    if 0 <= changed_pixel <= 255:\n",
        "      changed_input[index] = changed_pixel\n",
        "      changed_pred = cnn.predict_proba(np.array([changed_input]))\n",
        "      changed_dog_prob = changed_pred[0][0]\n",
        "      D = (changed_dog_prob - dog_prob)/pixel_change\n",
        "      D_list.append(np.abs(D))\n",
        "  saliency = np.mean(D_list)\n",
        "  saliencies.append(saliency)\n",
        "\n",
        "print (saliencies)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEAJ5VinTIZ"
      },
      "source": [
        "You'll notice that your saliencies are probably very small values, since each individual pixel has a small effect on the output.\n",
        "Here are the current min and max:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5vRrciYnZgk"
      },
      "source": [
        "sal_array = np.array(saliencies)\n",
        "print (sal_array.min(), sal_array.max())\n",
        "print (sal_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQfwv6rnl--"
      },
      "source": [
        "To plot the saliencies, we need to do some arithmetic to transform them to a range of 0 to 1. Can you explain the function of each line?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL_W9k0W0Sai"
      },
      "source": [
        "sal_array = np.array(saliencies)\n",
        "sal_array = sal_array - sal_array.min()\n",
        "#TODO print min and max\n",
        "\n",
        "sal_array = sal_array / sal_array.max()\n",
        "#TODO print min and max\n",
        "\n",
        "#Can you perform this transformation in a single line of code?\n",
        "\n",
        "print (sal_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP5IbZf8pl-l",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "print (sal_array.min(), sal_array.max())\n",
        "sal_array = (sal_array - sal_array.min()) / (sal_array.max() - sal_array.min())\n",
        "print (sal_array.min(), sal_array.max())\n",
        "sal_array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFKoff4n_gf"
      },
      "source": [
        "Finally, we can plot our saliency map!\n",
        "\n",
        "If you're not getting great results, try experimenting with how much you're changing the pixel values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vANcgvj1Pvc"
      },
      "source": [
        "#Plot our original image\n",
        "plt.imshow(input_image.reshape(32,32,3).astype(int))\n",
        "plt.show()\n",
        "\n",
        "#Plot our saliency map: the brighter, the higher the saliency\n",
        "plt.imshow(sal_array.reshape(32,32,3))\n",
        "plt.show()\n",
        "\n",
        "#Plot our saliency map superimposed on the image\n",
        "plt.imshow(input_image.reshape(32,32,3).astype(int))\n",
        "plt.imshow(sal_array.reshape(32,32,3),alpha=0.6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fistwbaDp56y"
      },
      "source": [
        "We now have some insight into our neural network! We know which pixels matter in its decisions.\n",
        "\n",
        "You can experiment with the definition of saliency we used above; you might come up with a better way to measure it!"
      ]
    }
  ]
}